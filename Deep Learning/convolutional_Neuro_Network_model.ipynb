{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Convolutional Neural Networks Modelling\n",
    "\n",
    "-Build and train a convolutional Neuro network to detect if there is a dog or cat in the dog\n",
    "\n",
    "##### Understanding the [Dataset](../dataFiles/Churn_Modelling.csv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\fssemwanga\\appdata\\roaming\\python\\python311\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\fssemwanga\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\fssemwanga\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\fssemwanga\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\fssemwanga\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\fssemwanga\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\fssemwanga\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\fssemwanga\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\fssemwanga\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\fssemwanga\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.24.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\fssemwanga\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\fssemwanga\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\fssemwanga\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.57.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\fssemwanga\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\fssemwanga\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\fssemwanga\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\fssemwanga\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\fssemwanga\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\fssemwanga\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\fssemwanga\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\fssemwanga\\appdata\\roaming\\python\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\fssemwanga\\appdata\\roaming\\python\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\fssemwanga\\appdata\\roaming\\python\\python311\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\fssemwanga\\appdata\\roaming\\python\\python311\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "# Install tensorflow\n",
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# module for preprocessing images, needed for image data generator\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Split original images into training and test set***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "#define folder paths\n",
    "dogs_folder = '../dataFiles/PetImages/Dog/'\n",
    "cats_folder = '../dataFiles/PetImages/Cat/'\n",
    "train_folder = '../dataFiles/train'\n",
    "test_folder = '../dataFiles/test'\n",
    "#define split ratio\n",
    "split_ratio = 0.7\n",
    "\n",
    "#list the files in in the dog and cat folders\n",
    "dog_files = os.listdir(dogs_folder)\n",
    "cat_files = os.listdir(cats_folder)\n",
    "#shuffle filenames - remove file arrangement biases e.g. breed sorting\n",
    "random.shuffle(dog_files)\n",
    "random.shuffle(cat_files)\n",
    "#calculate split index i.e. position where the split will occur\n",
    "dog_split_idx = int(len(dog_files) * split_ratio)\n",
    "cat_split_idx = int(len(cat_files) * split_ratio)\n",
    "print(f'Dog Split index: {dog_split_idx}| Cat Spit Index: {cat_split_idx }')\n",
    "# Split the files into training and test sets\n",
    "dog_train = dog_files[:dog_split_idx]\n",
    "dog_test = dog_files[dog_split_idx:]\n",
    "cat_train = cat_files[:cat_split_idx]\n",
    "cat_test = cat_files[cat_split_idx:]\n",
    "\n",
    "# Create the training and test directories if they don't exist\n",
    "os.makedirs(os.path.join(train_folder, 'dog'), exist_ok=True)\n",
    "os.makedirs(os.path.join(train_folder, 'cat'), exist_ok=True)\n",
    "os.makedirs(os.path.join(test_folder, 'cat'), exist_ok=True)\n",
    "os.makedirs(os.path.join(test_folder, 'dog'), exist_ok=True)\n",
    "\n",
    "# Copy dog images to training and test directories\n",
    "for file in dog_train:\n",
    "    src_path = os.path.join(dogs_folder, file)\n",
    "    dest_path = os.path.join(train_folder, 'dog', file)\n",
    "    shutil.copy(src_path, dest_path)\n",
    "\n",
    "for file in dog_test:\n",
    "    src_path = os.path.join(dogs_folder, file)\n",
    "    dest_path = os.path.join(test_folder, 'dog', file)\n",
    "    shutil.copy(src_path, dest_path)\n",
    "\n",
    "# Copy cat images to training and test directories\n",
    "for file in cat_train:\n",
    "    src_path = os.path.join(cats_folder, file)\n",
    "    dest_path = os.path.join(train_folder, 'cat', file)\n",
    "    shutil.copy(src_path, dest_path)\n",
    "\n",
    "for file in cat_test:\n",
    "    src_path = os.path.join(cats_folder, file)\n",
    "    dest_path = os.path.join(test_folder, 'cat', file)\n",
    "    shutil.copy(src_path, dest_path)\n",
    "\n",
    "print(\"Data split and copied successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the Training Set\n",
    "- Apply transformations on the images of the training set to avoid over fitting if we ***DONOT*** apply transformations when training the CNN on the test set we will have huge differences between the accuracy on the training set and the one on the evaluation set. Higher accuracy on the training set i.e. 98% and much lower accuracy on the test set  is referred to as **Over fitting**.\n",
    "- applying transformations avoids over fitting.\n",
    "- Geometrical transformations could include - Zoom e.g. Zoom in and Zoom out, rotations, transvection i.e. shifting some of the pixels , horizontal flips - this processing is referred to as ***image augmentation*** - ensures that the CNN is not over trained on the existing images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instance of image of the data generator class\n",
    "#rescale will apply feature scaling on the pixels\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "#connect the instance and connect it to the dataset\n",
    "#Parameters - target size of 64 gives reasonable training time, Class mode is binary because outcome is binary i.e. cat or dog\n",
    "training_set= train_datagen.flow_from_directory(\n",
    "        '../dataFiles/train',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13237 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# No transformations should be performed on the test images\n",
    "# However they must be re-scaled / feature/pixel scaled\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#importing the test set images into the notebook\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        '../dataFiles/test',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Building the CNN\n",
    "\n",
    "- Initialise the CNN as a sequence of layers\n",
    "- Add the input layer and the first hidden layer composed a certian number of neurons\n",
    "- add a second hidden layer to build a deep learning model instead of a shallow learning model\n",
    "- finally add the output layer which will predict our output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Initialising the CNN***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an artificial neural network as a sequence of layers\n",
    "cnn = tf.keras.models.Sequential()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Step 1: Convolution***\n",
    "- add the Convolutional layer as a object of the Conv2D class\n",
    "- Filters / Kernels - number of feature detectors - classic architecture uses 32 filters in the first and second convolution layers\n",
    "- Kernel Size - size of the feature detector i.e. square array of feature detector\n",
    "- Activation parameter - needs to be ***'Relu'*** which is the rectifier function - required as long as we have not reached the last layer\n",
    "- input_shape - for the very first layer you need to put the input layer.  Input shape is (64,64, 3) because we are working with coloured images (RGB) for black and white images we would have (64,64, 1) first two parameter correspond to target size used in data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a convolutional layer to the CNN\n",
    "cnn.add(tf.keras.layers.Conv2D(filters =32, kernel_size=3, activation='relu', input_shape=[64,64, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Step 2 Pooling***\n",
    "- adding the Pooling layers\n",
    "- Max pooling layer\n",
    "- Pool_size illustration\n",
    "- stride - refers to the stride\n",
    "- padding is the parameter used when we get to the end of the feature map when max pooling -keep the default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, stride=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Adding a second Convolution Layer***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second convolution layer - removing the input shape parameter as we are now on the second convolution layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters =32, kernel_size=3, activation='relu' ))\n",
    "#pooling\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Step 3 Flattening***\n",
    "- flattening the results of all convolutions and poolings into a 1D vector which becomes the input of a future fully connected ANN\n",
    "- Using the Flatten Class which takens no parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Step 4 Full Connection***\n",
    "- units - number of hidden neurons - 128 hidden neurons as the problem is more complex\n",
    "- activation function - use rectifier as we have not reached the final output layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a fully connected layer\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Step 5: Output layer***\n",
    "- number of neurons in the output layer is 1 as we are doing binary classification\n",
    "- activation function for the output layer should be ***Sigmoid*** and if we has more classes in the output we would use ***softmax***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 - Training the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Compiling the ANN***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Training the CNN on the Training Dataset and evaluating it on the Test set***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Making a single prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
