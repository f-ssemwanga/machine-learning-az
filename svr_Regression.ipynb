{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Consider an HR department trying to hire someone and they are trying to predict previous salary of an employer.***\n",
    "- The Model will predict a salary based on the position of the employee in their previous role\n",
    "\n",
    "- Consider the data [Position_Salary.csv](Position_Salaries.csv)\n",
    "\n",
    "- Note that with SVR you need to apply feature scaling because the SVR model does not have the explicit linear equations with coefficients that standardise / compensate for the differences between the lower value features and higher value features\n",
    "-SVR has an implicit equation / relationship of dependent variables with respect to features hence why feature scaling is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Import Libraries***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Importing the dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1]\n",
      " [ 2]\n",
      " [ 3]\n",
      " [ 4]\n",
      " [ 5]\n",
      " [ 6]\n",
      " [ 7]\n",
      " [ 8]\n",
      " [ 9]\n",
      " [10]]\n",
      "[  45000   50000   60000   80000  110000  150000  200000  300000  500000\n",
      " 1000000]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('Position_Salaries.csv')\n",
    "x = dataset.iloc[:, 1:-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "print(f'{x}\\n{y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Feature Scaling***\n",
    "- This is a required step because the salaries are way higher than the levels Feature\n",
    "- This is required to put the values in the same range\n",
    "**Other Instances where feature scaling is necessary**\n",
    "- Don't apply feature scaling to dummy variables resulting from OneHotEncoding\n",
    "- When a dependent variable takes binary values e.g. 0,1 you do not have to apply feature scaling because the values are in the right range\n",
    "- When the dependent variable takes super high values with respect to the other values then you need to apply feature scaling to put all the features and dependent variables in the same range\n",
    "- Feature scaling must be applied to data after the split if data is split into training and test sets\n",
    "- Finally you might need to inverse feature scaling at the end to revert to the original scales when explaining results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1]\n",
      " [ 2]\n",
      " [ 3]\n",
      " [ 4]\n",
      " [ 5]\n",
      " [ 6]\n",
      " [ 7]\n",
      " [ 8]\n",
      " [ 9]\n",
      " [10]]\n",
      "[  45000   50000   60000   80000  110000  150000  200000  300000  500000\n",
      " 1000000]\n",
      "[[  45000]\n",
      " [  50000]\n",
      " [  60000]\n",
      " [  80000]\n",
      " [ 110000]\n",
      " [ 150000]\n",
      " [ 200000]\n",
      " [ 300000]\n",
      " [ 500000]\n",
      " [1000000]]\n"
     ]
    }
   ],
   "source": [
    "print(f'{x}\\n{y}')\n",
    "\n",
    "#reshape y into a 2d array because the StandardScalar class which performs the scaling expects a 2D array\n",
    "y = y.reshape(len(y), 1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.5666989 ]\n",
      " [-1.21854359]\n",
      " [-0.87038828]\n",
      " [-0.52223297]\n",
      " [-0.17407766]\n",
      " [ 0.17407766]\n",
      " [ 0.52223297]\n",
      " [ 0.87038828]\n",
      " [ 1.21854359]\n",
      " [ 1.5666989 ]]\n",
      "[[-0.72004253]\n",
      " [-0.70243757]\n",
      " [-0.66722767]\n",
      " [-0.59680786]\n",
      " [-0.49117815]\n",
      " [-0.35033854]\n",
      " [-0.17428902]\n",
      " [ 0.17781001]\n",
      " [ 0.88200808]\n",
      " [ 2.64250325]]\n"
     ]
    }
   ],
   "source": [
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x= StandardScaler()\n",
    "x= sc_x.fit_transform(x)\n",
    "\n",
    "# create a separate StandardScalar object dependent feature as we cannot use the same object we used on the independent variables\n",
    "#this is because the sc object computes the mean and standard deviation of the dependent features and since both features are different\n",
    "#a different StandardScalar object is required\n",
    "sc_y = StandardScaler()\n",
    "y = sc_y.fit_transform(y)\n",
    "print(f'{x}\\n{y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Training the SVR Model on the whole Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Predicting a new result***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Visualising the SVR results***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Visualising the SVR Results (for higher resolution and smoother curve)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
